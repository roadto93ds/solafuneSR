{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "import tifffile\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import functional as tvf\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchsr\n",
    "\n",
    "import timm\n",
    "import timm.scheduler\n",
    "\n",
    "import kornia\n",
    "import kornia.augmentation as K\n",
    "import kornia.utils\n",
    "\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure # ssim\n",
    "\n",
    "from madgrad import MADGRAD\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG_set:\n",
    "    EPOCHS = 200 ### 0 ~ 200\n",
    "    # EPOCHS = 100 ### 201 ~ 300 / 301 ~ 400\n",
    "    OPTIMIZER = \"MADGRAD(net.parameters(),lr=2e-5/2,weight_decay=1e-6/2)\" ### 0 ~ 200 / 201 ~ 300\n",
    "    # OPTIMIZER = \"MADGRAD(net.parameters(),lr=2e-5/3,weight_decay=1e-6/3)\" ### 301 ~ 400\n",
    "\n",
    "class CFG:\n",
    "    MODEL_NAME = \"myRCAN\"\n",
    "    VERSION = \"0330\"\n",
    "    LOAD_PARAM = None ### 0 ~ 200\n",
    "    # LOAD_PARAM = \"myRCAN_0330\" ### 201 ~ 400（追加訓練時、学習したパラメータを引き継ぎたいときはfolderを指定する）\n",
    "    DEVICE = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    N_FOLD = 5\n",
    "    BATCH_SIZE = 4\n",
    "    SEED = 0\n",
    "    NUM_WORKERS = 32\n",
    "    ROOT = \"/root/workspace/solafune_SR\"\n",
    "    DATA_DIR = os.path.join(ROOT, \"data\") # 直下に /train & /test\n",
    "    TRAIN_DIR = os.path.join(DATA_DIR, \"train\") # 直下に .tif *300\n",
    "    TEST_DIR = os.path.join(DATA_DIR, \"test\") # # 直下に .tif * 300\n",
    "    PARAM_DIR = os.path.join(ROOT, \"net_params\", f\"{MODEL_NAME}_{VERSION}\")\n",
    "\n",
    "    SUBMISSION_TIF_DIR = os.path.join(ROOT, \"submission_tif\", f\"{MODEL_NAME}_{VERSION}\")\n",
    "\n",
    "os.makedirs(CFG.PARAM_DIR, exist_ok=True)\n",
    "os.makedirs(CFG.SUBMISSION_TIF_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=================================================\")\n",
    "print(f\"MODEL_NAME : {CFG.MODEL_NAME} - VERSION : {CFG.VERSION}\")\n",
    "print(f\"LOAD_PARAM : {CFG.LOAD_PARAM}\")\n",
    "print(f\"EPOCHS : {CFG_set.EPOCHS}   BATCH_SIZE : {CFG.BATCH_SIZE}\")\n",
    "print(f\"ROOT : {CFG.ROOT}\")\n",
    "print(f\"data_dir : {CFG.DATA_DIR}\")\n",
    "print(f\"train_dir : {CFG.TRAIN_DIR}\")\n",
    "print(f\"test_dir : {CFG.TEST_DIR}\")\n",
    "print(f\"param_dir : {CFG.PARAM_DIR}\")\n",
    "print(f\"submission_dir : {CFG.SUBMISSION_TIF_DIR}\") ### .tif output\n",
    "print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(train_dir, test_dir):\n",
    "    train_filepath = os.path.join(train_dir, \"*.tif\") # low & high pair\n",
    "    test_filepath = os.path.join(test_dir, \"*.tif\")\n",
    "\n",
    "    train_low_pathlist = [ train_path for train_path in glob.glob(train_filepath) if train_path.find('low') != -1]\n",
    "    train_high_pathlist = [ train_path for train_path in glob.glob(train_filepath) if train_path.find('high') != -1]\n",
    "\n",
    "    train_low_pathlist = sorted(train_low_pathlist)\n",
    "    train_high_pathlist = sorted(train_high_pathlist)\n",
    "    test_pathlist = sorted(glob.glob(test_filepath))\n",
    "\n",
    "    all_df = pd.DataFrame({\n",
    "        \"low_path\": train_low_pathlist,\n",
    "        \"high_path\":train_high_pathlist\n",
    "    })\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        \"test_path\":test_pathlist\n",
    "    })\n",
    "    \n",
    "    return all_df, test_df\n",
    "\n",
    "def torch_seed(seed=0):\n",
    "    \"\"\"Fixed seed value.\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "torch_seed(CFG.SEED)\n",
    "\n",
    "def visualize_process(train_loss_log, valid_loss_log, train_acc_log, valid_acc_log, title_=\"Acc\"):\n",
    "    \"\"\"\n",
    "    4params = def training 's return\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss_log, label=\"train\")\n",
    "    plt.plot(valid_loss_log, label=\"valid\")\n",
    "    plt.title(\"Loss_log\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_acc_log, label=\"train\")\n",
    "    plt.plot(valid_acc_log, label=\"valid\")\n",
    "    plt.title(f\"{title_}_log\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalFlipTransform:\n",
    "    def __init__(self):\n",
    "        self.p = random.randint(0,1)\n",
    "\n",
    "    def __call__(self, img_t:torch.tensor):\n",
    "        if self.p == 1:\n",
    "            return torchvision.transforms.functional.hflip(img_t)\n",
    "        else:\n",
    "            return img_t\n",
    "\n",
    "class VerticalFlipTransform:\n",
    "    def __init__(self):\n",
    "        self.p = random.randint(0,1)\n",
    "\n",
    "    def __call__(self, img_t:torch.tensor):\n",
    "        if self.p == 1:\n",
    "            return torchvision.transforms.functional.vflip(img_t)\n",
    "        else:\n",
    "            return img_t\n",
    "\n",
    "class RotateTransform:\n",
    "    def __init__(self):\n",
    "        self.angle = random.choice([0,90,180,270])\n",
    "\n",
    "    def __call__(self, img_t:torch.tensor):\n",
    "        return torchvision.transforms.functional.rotate(img_t, self.angle)\n",
    "    \n",
    "class ChannelShuffle:\n",
    "    def __init__(self):\n",
    "        self.p = random.randint(0,1)\n",
    "        self.order = random.sample([0,1,2], 3)\n",
    "\n",
    "    def __call__(self, img_t:torch.tensor):\n",
    "        if self.p == 1:\n",
    "            img_t_s = img_t.clone()\n",
    "            img_t_s[0], img_t_s[1], img_t_s[2] = img_t[self.order[0]], img_t[self.order[1]], img_t[self.order[2]]\n",
    "            return img_t_s\n",
    "        else:\n",
    "            return img_t\n",
    "        \n",
    "class ColorJitter:\n",
    "    def __init__(self):\n",
    "        self.p = random.randint(0,1)\n",
    "\n",
    "    def __call__(self, low_t, high_t):\n",
    "        if self.p == 1:\n",
    "            jitter = K.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1., keepdim=True)\n",
    "            low_t = jitter(low_t)\n",
    "            high_t = jitter(high_t, jitter._params)\n",
    "            return low_t, high_t\n",
    "        else:\n",
    "            return low_t, high_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path(net_, net_path, device_):\n",
    "    net_.load_state_dict(torch.load(net_path, map_location=device_))\n",
    "    return net_\n",
    "\n",
    "class train_ImageTransform():\n",
    "    def __init__(self):\n",
    "        self.low_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        self.high_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "    def __call__(self, low_img, high_img):\n",
    "        low_t, high_t = self.low_transform(low_img), self.high_transform(high_img)\n",
    "        ### 1 ~ 400\n",
    "        Rotater = RotateTransform()\n",
    "        low_t, high_t = Rotater(low_t), Rotater(high_t)\n",
    "        H_flip = HorizontalFlipTransform()\n",
    "        low_t, high_t = H_flip(low_t), H_flip(high_t)\n",
    "        V_flip = VerticalFlipTransform()\n",
    "        low_t, high_t = V_flip(low_t), V_flip(high_t)\n",
    "        ### 1 ~ 201\n",
    "        C_shuffle = ChannelShuffle()\n",
    "        low_t, high_t = C_shuffle(low_t), C_shuffle(high_t)\n",
    "        jitter = ColorJitter()\n",
    "        low_t, high_t = jitter(low_t, high_t)\n",
    "        return low_t, high_t\n",
    "\n",
    "class valid_ImageTransform():\n",
    "    def __init__(self):\n",
    "        self.low_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "        self.high_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "\n",
    "    def __call__(self, low_img, high_img):\n",
    "        low_t = self.low_transform(low_img)\n",
    "        high_t = self.high_transform(high_img)\n",
    "        return low_t, high_t\n",
    "    \n",
    "class sub_ImageTransform():\n",
    "    def __init__(self):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df) \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        low_img_path = row.low_path\n",
    "        high_img_path = row.high_path\n",
    "        low_t, high_t = self.transform(tifffile.imread(low_img_path), tifffile.imread(high_img_path))\n",
    "        return low_t, high_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RCAN_():\n",
    "    net = torchsr.models.rcan(scale=4, pretrained=True)\n",
    "    ### x4 -> x5\n",
    "    m = list()\n",
    "    conv1 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    ps1 = nn.PixelShuffle(2)\n",
    "    aap = nn.AdaptiveAvgPool2d((325,325))\n",
    "    conv2 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    ps2 = nn.PixelShuffle(2)\n",
    "    conv_last = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.append(conv1)\n",
    "    m.append(ps1)\n",
    "    m.append(aap)\n",
    "    m.append(conv2)\n",
    "    m.append(ps2)\n",
    "    m.append(conv_last)\n",
    "    tail_re = nn.Sequential(*m)\n",
    "    for m in tail_re.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "    net.tail = tail_re\n",
    "    return net\n",
    "\n",
    "def CARN_():\n",
    "    net = torchsr.models.carn(scale=4, pretrained=True)\n",
    "    ### x4 -> x5\n",
    "    m = list()\n",
    "    conv1 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    reru1 = nn.ReLU(inplace=True)\n",
    "    ps1 = nn.PixelShuffle(2)\n",
    "    aap = nn.AdaptiveAvgPool2d((325,325))\n",
    "    conv2 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    relu2 = nn.ReLU(inplace=True)\n",
    "    ps2 = nn.PixelShuffle(2)\n",
    "    m.append(conv1)\n",
    "    m.append(reru1)\n",
    "    m.append(ps1)\n",
    "    m.append(aap)\n",
    "    m.append(conv2)\n",
    "    m.append(relu2)\n",
    "    m.append(ps2)\n",
    "    upsample_re = nn.Sequential(*m)\n",
    "    for m in upsample_re.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "    net.upsample.up4.body = upsample_re\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training\n",
    "def train_epoch(net, train_dataloader, ssim, optimizer, device):\n",
    "    net.train()\n",
    "    n_train = 0\n",
    "    loss_total, ssim_total = 0,0\n",
    "    for low_imgs, high_imgs in tqdm(train_dataloader):\n",
    "        n_train += len(high_imgs)\n",
    "        low_imgs, high_imgs = low_imgs.to(device, non_blocking=True), high_imgs.to(device, non_blocking=True)\n",
    "        ssim.reset() # torch metrics\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(low_imgs)\n",
    "        loss = 1 - ssim(outputs, high_imgs) # criterion with GPU\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_total += loss.item()*len(high_imgs)\n",
    "        ssim_total += (1-loss.item())*len(high_imgs) # ssim = 1 - train_loss\n",
    "    return loss_total/n_train, ssim_total/n_train\n",
    "\n",
    "### validation\n",
    "def valid_epoch(net, valid_dataloader, ssim, device):\n",
    "    net.eval()\n",
    "    n_valid = 0\n",
    "    loss_total, ssim_total = 0,0\n",
    "    with torch.no_grad():\n",
    "        for low_imgs, high_imgs in valid_dataloader:\n",
    "            n_valid += len(high_imgs)\n",
    "            low_imgs, high_imgs = low_imgs.to(device, non_blocking=True), high_imgs.to(device, non_blocking=True)\n",
    "            ssim.reset() # torch metrics\n",
    "            outputs = net(low_imgs)\n",
    "            loss = 1 - ssim(outputs, high_imgs) # criterion with GPU\n",
    "            loss_total += loss.item()*len(high_imgs)\n",
    "            ssim_total += (1-loss.item())*len(high_imgs) # ssim = 1 - valid_loss\n",
    "    return loss_total/n_valid, ssim_total/n_valid\n",
    "\n",
    "### loop(training+validation)\n",
    "def loop(cv, net, epochs, train_dataloader, valid_dataloader, scheduler, optimizer, device):\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device) # criterion with GPU\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    train_loss_log, train_ssim_log = list(), list()\n",
    "    valid_loss_log, valid_ssim_log = list(), list()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_ssim = train_epoch(net, train_dataloader, ssim, optimizer, device)\n",
    "        valid_loss, valid_ssim = valid_epoch(net, valid_dataloader, ssim, device)\n",
    "        scheduler.step(epoch) # for timm\n",
    "\n",
    "        train_loss_log.append(train_loss)\n",
    "        train_ssim_log.append(train_ssim)\n",
    "        valid_loss_log.append(valid_loss)\n",
    "        valid_ssim_log.append(valid_ssim)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], train_loss: {train_loss_log[epoch]:.5f}, train_ssim: {train_ssim_log[epoch]:.5f}\", end=\" \")\n",
    "        print(f\"valid_loss: {valid_loss_log[epoch]:.5f}, valid_ssim: {valid_ssim_log[epoch]:.5f}\")\n",
    "\n",
    "        ### save\n",
    "        if np.argmax(valid_ssim_log) == epoch:\n",
    "            torch.save(net.state_dict(), os.path.join(CFG.PARAM_DIR, f\"ssim_cv{cv:02d}.pth\"))\n",
    "\n",
    "    return train_loss_log, train_ssim_log, valid_loss_log, valid_ssim_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df, test_df = get_df(CFG.TRAIN_DIR, CFG.TEST_DIR) # (3000, 2) (400, 1)\n",
    "test_path_list = test_df[\"test_path\"].tolist()\n",
    "\n",
    "train_transform = train_ImageTransform()\n",
    "valid_transform = valid_ImageTransform()\n",
    "sub_transform = sub_ImageTransform()\n",
    "\n",
    "device = CFG.DEVICE\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "kf = KFold(n_splits=CFG.N_FOLD, shuffle=True, random_state=CFG.SEED)\n",
    "cv = 0\n",
    "\n",
    "for train_index, valid_index in kf.split(all_df):\n",
    "    net = RCAN_().to(CFG.DEVICE)\n",
    "    cv +=1\n",
    "\n",
    "    if CFG.LOAD_PARAM is not None:\n",
    "        load_dir = os.path.join(CFG.ROOT, \"net_params\", CFG.LOAD_PARAM)\n",
    "        net_path = os.path.join(load_dir, f\"ssim_cv{cv:02d}.pth\")\n",
    "        print(net_path)\n",
    "        net = load_path(net, net_path, CFG.DEVICE)\n",
    "\n",
    "    print(f\"*************** fold:{cv} ***************\")\n",
    "    train_df, valid_df = all_df.iloc[train_index], all_df.iloc[valid_index]\n",
    "    train_dataset = ImageDataset(train_df, transform=train_transform)\n",
    "    valid_dataset = ImageDataset(valid_df, transform=valid_transform)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=CFG.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    epochs = CFG_set.EPOCHS\n",
    "    optimizer = eval(CFG_set.OPTIMIZER)\n",
    "\n",
    "    ### tanh_scheduler / 1~200\n",
    "    scheduler = timm.scheduler.TanhLRScheduler(optimizer, \n",
    "                                                    t_initial=epochs,\n",
    "                                                    lr_min=1e-8,\n",
    "                                                    t_in_epochs=True,\n",
    "                                                    lb=-6, ub=4,\n",
    "                                                    warmup_t = 30, warmup_lr_init=1e-8)\n",
    "\n",
    "    ## Anealing_scheduler / 201 ~ 400\n",
    "    # scheduler = timm.scheduler.CosineLRScheduler(optimizer,\n",
    "    #                                                     t_initial=20,\n",
    "    #                                                     lr_min=1e-8,\n",
    "    #                                                     t_in_epochs=True,\n",
    "    #                                                     cycle_limit=5,\n",
    "    #                                                     cycle_decay=0.8,\n",
    "    #                                                     cycle_mul=1.0)\n",
    "\n",
    "\n",
    "    train_loss_log, train_ssim_log, valid_loss_log, valid_ssim_log = \\\n",
    "        loop(cv, net, epochs, train_dataloader, valid_dataloader, scheduler, optimizer, device)\n",
    "\n",
    "    ##### result #####\n",
    "    sns.set()\n",
    "    visualize_process(train_loss_log, valid_loss_log, train_ssim_log, valid_ssim_log, title_=\"SSIM\")\n",
    "\n",
    "    print(f\"*************** fold:{cv} ***************\")\n",
    "    best_ssim_ind = np.argmax(valid_ssim_log) # 0からカウント\n",
    "    print(f\"Epoch [{best_ssim_ind+1}/{epochs}], train_loss: {train_loss_log[best_ssim_ind]:.5f}, train_ssim: {train_ssim_log[best_ssim_ind]:.5f}\", end=\" \")\n",
    "    print(f\"valid_loss: {valid_loss_log[best_ssim_ind]:.5f}, valid_ssim: {valid_ssim_log[best_ssim_ind]:.5f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"param_dir : {CFG.PARAM_DIR}\")\n",
    "print(sorted(os.listdir(CFG.PARAM_DIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phv_clipnp(test_path, clip_min=0, clip_max=1, rotate90 = False):\n",
    "    \"\"\"\n",
    "    input : test_path\n",
    "    output : output_0_np, output_h_np, output_v_np, output_hv_np\n",
    "        dtype : float32 clip(clip_min, clip_max) 済みを返す\n",
    "    rotate90 : True\n",
    "        input_ = torchvision.transforms.functional.rotate(img_t, 90)\n",
    "        後で -90 して戻す\n",
    "    rotate90=False と rotate90=True の return 使えば 8パターン\n",
    "    \"\"\"\n",
    "    input_ = tifffile.imread(test_path) # numpy (130, 130, 3)\n",
    "    input_ = sub_transform(input_) # torch.Size([3, 130, 130])\n",
    "    ### rotate90\n",
    "    if rotate90:\n",
    "        input_ = torchvision.transforms.functional.rotate(input_, 90)\n",
    "    ### 回転なし\n",
    "    input_0 = input_.unsqueeze(0).to(CFG.DEVICE) # torch.Size([1, 3, 130, 130])\n",
    "    output_0 = net(input_0) # torch.Size([1, 3, 650, 650]) / torch.float32 / マイナスもある\n",
    "    output_0 = output_0.squeeze()\n",
    "    ### hflip\n",
    "    input_h = tvf.hflip(input_)\n",
    "    input_h = input_h.unsqueeze(0).to(CFG.DEVICE)\n",
    "    output_h = net(input_h)\n",
    "    output_h = output_h.squeeze() ### hflip\n",
    "    output_h = tvf.hflip(output_h) ### hfilpを戻す\n",
    "    ### vflip\n",
    "    input_v = tvf.vflip(input_)\n",
    "    input_v = input_v.unsqueeze(0).to(CFG.DEVICE)\n",
    "    output_v = net(input_v)\n",
    "    output_v = output_v.squeeze() ### vflip\n",
    "    output_v = tvf.vflip(output_v) ### vfilpを戻す\n",
    "    ### hflip + vflip\n",
    "    input_h = tvf.hflip(input_)\n",
    "    input_hv = tvf.vflip(input_h)\n",
    "    input_hv = input_hv.unsqueeze(0).to(CFG.DEVICE)\n",
    "    output_hv = net(input_hv)\n",
    "    output_hv = output_hv.squeeze() ### hvflip\n",
    "    output_hv = tvf.vflip(output_hv) ### vfilpを戻す\n",
    "    output_hv = tvf.hflip(output_hv) ### hflipを戻す\n",
    "    ### rotate90戻す\n",
    "    if rotate90:\n",
    "        output_0 = tvf.rotate(output_0, -90)\n",
    "        output_h = tvf.rotate(output_h, -90)\n",
    "        output_v = tvf.rotate(output_v, -90)\n",
    "        output_hv = tvf.rotate(output_hv, -90)\n",
    "    ### to_numpy\n",
    "    output_0_np = output_0.cpu().detach().numpy().transpose((1,2,0)) # numpy (650, 650, 3) / float32 / マイナスもある\n",
    "    output_0_np = np.clip(output_0_np, clip_min, clip_max) ### uint8 にする前にclipしとく\n",
    "    output_h_np = output_h.cpu().detach().numpy().transpose((1,2,0)) \n",
    "    output_h_np = np.clip(output_h_np, clip_min, clip_max)\n",
    "    output_v_np = output_v.cpu().detach().numpy().transpose((1,2,0)) \n",
    "    output_v_np = np.clip(output_v_np, clip_min, clip_max)\n",
    "    output_hv_np = output_hv.cpu().detach().numpy().transpose((1,2,0)) \n",
    "    output_hv_np = np.clip(output_hv_np, clip_min, clip_max)\n",
    "    return output_0_np, output_h_np, output_v_np, output_hv_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zip(net, net_path_list, N_FOLD=5):\n",
    "    evok = 0 ### 許容値\n",
    "    clip_min, clip_max = 0-evok, 1+evok\n",
    "\n",
    "    for test_path in test_path_list:\n",
    "        pred_np = 0 # N_FOLD の数だけ予測したnpを積んでいく\n",
    "        for net_path in net_path_list:\n",
    "            net = load_path(net, net_path, CFG.DEVICE)\n",
    "            net.eval()\n",
    "            output_0_np, output_h_np, output_v_np, output_hv_np = get_phv_clipnp(test_path, clip_min=clip_min, clip_max=clip_max, rotate90 = False)\n",
    "            output_0_np90, output_h_np90, output_v_np90, output_hv_np90 = get_phv_clipnp(test_path, clip_min=clip_min, clip_max=clip_max, rotate90 = True)\n",
    "            output_bind = (output_0_np + output_h_np + output_v_np + output_hv_np + output_0_np90 + output_h_np90 + output_v_np90 + output_hv_np90)/8\n",
    "            pred_np += output_bind\n",
    "        pred_np /= N_FOLD\n",
    "        ### get_phv_clipnp で clip 幅を少し広めにするのであれば、ここでもう一回 bind を clip\n",
    "        pred_np = np.clip(pred_np, 0, 1)\n",
    "        pred_np = pred_np*255\n",
    "        pred_np = np.round(pred_np)\n",
    "        pred_np = pred_np.astype(\"uint8\") # 画像を1枚に確定\n",
    "        ### 書き出し\n",
    "        filename = test_path.split(\"/\")[-1]\n",
    "        sub_filename = filename.replace(\"low\", \"answer\")\n",
    "        tifffile.imwrite(os.path.join(CFG.SUBMISSION_TIF_DIR, sub_filename), pred_np, photometric='rgb')\n",
    "\n",
    "    ### 圧縮したいフォルダのパス\n",
    "    base_ = CFG.SUBMISSION_TIF_DIR\n",
    "    shutil.make_archive(f\"{base_}_TTA\", format='zip', root_dir=base_)\n",
    "    print(f\"output_zip : {base_}_TTA.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RCAN_().to(CFG.DEVICE)\n",
    "# test_path_list = test_df[\"test_path\"].tolist()\n",
    "test_path_list = test_df[\"test_path\"].tolist()[0:10]\n",
    "net_path_list = [os.path.join(CFG.PARAM_DIR, f\"ssim_cv{cv:02d}.pth\") for cv in range(1,CFG.N_FOLD+1)]\n",
    "print(net_path_list)\n",
    "sub_transform = sub_ImageTransform()\n",
    "\n",
    "make_zip(net, net_path_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
